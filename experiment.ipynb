{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style-Preserving Speech-to-Speech Translation Experiment\n",
    "\n",
    "This notebook runs the experiment to determine the minimal duration of speaker embeddings required to effectively clone a speaker's voice across languages.\n",
    "\n",
    "## 1. Setup Environment\n",
    "Install necessary dependencies if running on Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only if needed, clear all files except experiment.ipynb\n",
    "# This command will remove all files and folders in the current directory except \"experiment.ipynb\"\n",
    "import os\n",
    "\n",
    "for fname in os.listdir():\n",
    "    if fname != \"experiment.ipynb\":\n",
    "        if os.path.isdir(fname):\n",
    "            import shutil\n",
    "            shutil.rmtree(fname)\n",
    "        else:\n",
    "            os.remove(fname)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'CS479-SpeakerEmbeddings'...\n",
      "^C\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'CS479-SpeakerEmbeddings'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-542054201.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'git clone https://github.com/NathanAsayDong/CS479-SpeakerEmbeddings.git'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CS479-SpeakerEmbeddings\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Optional: Reload modules if you've already imported them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'CS479-SpeakerEmbeddings'"
     ]
    }
   ],
   "source": [
    "# Cell to refresh code from GitHub\n",
    "import os\n",
    "\n",
    "# Navigate to the repo directory\n",
    "if os.path.exists(\"CS479-SpeakerEmbeddings\"):\n",
    "    os.chdir(\"CS479-SpeakerEmbeddings\")\n",
    "    !git pull\n",
    "else:\n",
    "    !git clone https://github.com/NathanAsayDong/CS479-SpeakerEmbeddings.git\n",
    "    os.chdir(\"CS479-SpeakerEmbeddings\")\n",
    "\n",
    "# Optional: Reload modules if you've already imported them\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "# List of your custom modules to reload\n",
    "modules_to_reload = [\n",
    "    \"common_voice_dataset\",\n",
    "    \"setup_experiment\",\n",
    "    \"run_experiment\",\n",
    "    \"asr_service\",\n",
    "    \"translation_service\",\n",
    "    \"tts_service\",\n",
    "    \"embedding_service\",\n",
    "    \"synthetic_data_service\",\n",
    "    \"enums\"\n",
    "]\n",
    "\n",
    "for module_name in modules_to_reload:\n",
    "    if module_name in sys.modules:\n",
    "        importlib.reload(sys.modules[module_name])\n",
    "        print(f\"Reloaded {module_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %cd CS479-SpeakerEmbeddings\n",
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.2)\n",
      "Requirement already satisfied: speechbrain in /usr/local/lib/python3.12/dist-packages (1.0.3)\n",
      "Requirement already satisfied: soundfile in /usr/local/lib/python3.12/dist-packages (0.13.1)\n",
      "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
      "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.12/dist-packages (20250625)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (2.12.3)\n",
      "Requirement already satisfied: torchcodec in /usr/local/lib/python3.12/dist-packages (0.8.1)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
      "Requirement already satisfied: kagglehub[pandas-datasets] in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.12/dist-packages (from speechbrain) (1.2.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from speechbrain) (1.5.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from speechbrain) (1.16.3)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (from speechbrain) (2.9.0+cu126)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile) (2.0.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa) (3.1.0)\n",
      "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.6.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.4.2)\n",
      "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.0.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.1.2)\n",
      "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (10.8.0)\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.12.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.4.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile) (2.23)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (4.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.28 in /usr/local/lib/python3.12/dist-packages (from hyperpyyaml->speechbrain) (0.18.16)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.12/dist-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain) (0.2.15)\n",
      "Requirement already satisfied: sounddevice in /usr/local/lib/python3.12/dist-packages (0.5.3)\n",
      "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.12/dist-packages (from sounddevice) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from CFFI>=1.0->sounddevice) (2.23)\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "libportaudio2 is already the newest version (19.6.0-1.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!pip install torch transformers speechbrain soundfile librosa openai-whisper accelerate sentencepiece pydantic torchcodec datasets kagglehub[pandas-datasets]\n",
    "!pip install sounddevice\n",
    "!sudo apt-get install libportaudio2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Modules\n",
    "Import the experiment setup and runner classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add current directory to path if needed\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from enums import Language\n",
    "from setup_experiment import ExperimentSetup\n",
    "from run_experiment import ExperimentRunner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configure Experiment\n",
    "Define the parameters for the experiment: source/target languages and reference durations to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_LANG = Language.ENGLISH\n",
    "TARGET_LANG = Language.SPANISH\n",
    "DURATIONS = [1.0, 2.0, 3.0, 4.0, 5.0]\n",
    "NUM_SAMPLES_PER_DURATION = 5 # Number of unique speakers to test\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare Data\n",
    "This step:\n",
    "1. Downloads/Loads Common Voice dataset via KaggleHub.\n",
    "2. Selects `NUM_SPEAKERS` with sufficient data.\n",
    "3. Creates concatenated reference audio files for each duration.\n",
    "4. Generates a manifest for the experiment run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asr_service.py\t\t peoples_speech_dataset.py  setup_experiment.py\n",
      "common_voice_dataset.py  ProjectOutline.pdf\t    synthetic_data_service.py\n",
      "embedding_service.py\t __pycache__\t\t    tmp_model\n",
      "enums.py\t\t readMe\t\t\t    translation_service.py\n",
      "experiment.ipynb\t requirements.txt\t    tts_service.py\n",
      "libri_speech_dataset.py  run_experiment.py\n",
      "main.py\t\t\t Samples\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing experiment data: 5 samples for each of [1.0, 2.0, 3.0, 4.0, 5.0]s durations...\n",
      "Loading Common Voice dataset for language 'en'...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2211675537.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Prepare the manifest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmanifest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples_per_duration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_SAMPLES_PER_DURATION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Manifest ready with {len(manifest)} speakers.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/setup_experiment.py\u001b[0m in \u001b[0;36mprepare_data\u001b[0;34m(self, num_samples_per_duration)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mcv_lang_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"en\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_language\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mLanguage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENGLISH\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"es\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCommonVoiceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv_lang_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"dev\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mexperiment_manifest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/common_voice_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, language_code, split)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;31m# It's huge. Be careful.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loading Common Voice dataset for language '{language_code}'...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkagglehub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mozillaorg/common-voice\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Dataset path: {self.dataset_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/kagglehub/datasets.py\u001b[0m in \u001b[0;36mdataset_download\u001b[0;34m(handle, path, force_download)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_dataset_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Downloading Dataset: {h.to_url()} ...\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mEXTRA_CONSOLE_BLOCK\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregistry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_resolver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_download\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/kagglehub/registry.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mfails\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mimpl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_impls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/kagglehub/colab_cache_resolver.py\u001b[0m in \u001b[0;36mis_supported\u001b[0;34m(self, handle, *_, **__)\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mapi_client\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mColabClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         data = {\n\u001b[1;32m    105\u001b[0m             \u001b[0;34m\"owner\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mowner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/kagglehub/clients.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    413\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mColabEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcredentials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_kaggle_credentials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"Content-type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/kagglehub/config.py\u001b[0m in \u001b[0;36mget_kaggle_credentials\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0musername\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreds_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCREDENTIALS_JSON_USERNAME\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreds_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCREDENTIALS_JSON_KEY\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             )\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mis_in_colab_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcolab_secret\u001b[0m \u001b[0;34m:=\u001b[0m \u001b[0mget_colab_credentials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mKaggleApiCredentials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0musername\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolab_secret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musername\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolab_secret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/kagglehub/config.py\u001b[0m in \u001b[0;36mget_colab_credentials\u001b[0;34m()\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0musername\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_normalize_whitespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCOLAB_SECRET_USERNAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_normalize_whitespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCOLAB_SECRET_KEY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0musername\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/userdata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     60\u001b[0m   \u001b[0;31m# thread-safe.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0m_userdata_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     resp = _message.blocking_request(\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;34m'GetSecret'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'key'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     )\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "setup = ExperimentSetup(\n",
    "    source_language=SOURCE_LANG,\n",
    "    target_language=TARGET_LANG,\n",
    "    reference_durations=DURATIONS,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "# Prepare the manifest\n",
    "manifest = setup.prepare_data(num_samples_per_duration=NUM_SAMPLES_PER_DURATION)\n",
    "\n",
    "print(f\"Manifest ready with {len(manifest)} speakers.\")\n",
    "print(\"Sample Item:\", manifest[0] if manifest else \"No data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Experiment\n",
    "Execute the pipeline for each speaker and duration:\n",
    "1. Extract ground truth embedding (original speaker).\n",
    "2. Translate source text to Spanish.\n",
    "3. Synthesize Spanish speech using the reference audio (5s, 10s, etc.) for style.\n",
    "4. Compute Cosine Similarity between ground truth and output embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/spkrec-xvect-voxceleb' if not cached\n",
      "DEBUG:speechbrain.utils.fetching:Fetch: Local file found, creating symlink '/root/.cache/huggingface/hub/models--speechbrain--spkrec-xvect-voxceleb/snapshots/56895a2df401be4150a159f3a1c653f00051d477/hyperparams.yaml' -> '/content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/hyperparams.yaml'\n",
      "INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/spkrec-xvect-voxceleb' if not cached\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Collecting files (or symlinks) for pretraining in tmp_model.\n",
      "INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-xvect-voxceleb' if not cached\n",
      "DEBUG:speechbrain.utils.fetching:Fetch: Local file found, creating symlink '/root/.cache/huggingface/hub/models--speechbrain--spkrec-xvect-voxceleb/snapshots/56895a2df401be4150a159f3a1c653f00051d477/embedding_model.ckpt' -> '/content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/embedding_model.ckpt'\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"embedding_model\"] = /content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/embedding_model.ckpt\n",
      "INFO:speechbrain.utils.fetching:Fetch mean_var_norm_emb.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-xvect-voxceleb' if not cached\n",
      "DEBUG:speechbrain.utils.fetching:Fetch: Local file found, creating symlink '/root/.cache/huggingface/hub/models--speechbrain--spkrec-xvect-voxceleb/snapshots/56895a2df401be4150a159f3a1c653f00051d477/mean_var_norm_emb.ckpt' -> '/content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/mean_var_norm_emb.ckpt'\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"mean_var_norm_emb\"] = /content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/mean_var_norm_emb.ckpt\n",
      "INFO:speechbrain.utils.fetching:Fetch classifier.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-xvect-voxceleb' if not cached\n",
      "DEBUG:speechbrain.utils.fetching:Fetch: Local file found, creating symlink '/root/.cache/huggingface/hub/models--speechbrain--spkrec-xvect-voxceleb/snapshots/56895a2df401be4150a159f3a1c653f00051d477/classifier.ckpt' -> '/content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/classifier.ckpt'\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"classifier\"] = /content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/classifier.ckpt\n",
      "INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Fetching from HuggingFace Hub 'speechbrain/spkrec-xvect-voxceleb' if not cached\n",
      "DEBUG:speechbrain.utils.fetching:Fetch: Local file found, creating symlink '/root/.cache/huggingface/hub/models--speechbrain--spkrec-xvect-voxceleb/snapshots/56895a2df401be4150a159f3a1c653f00051d477/label_encoder.txt' -> '/content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/label_encoder.ckpt'\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"label_encoder\"] = /content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/label_encoder.ckpt\n",
      "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): embedding_model -> /content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/embedding_model.ckpt\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): mean_var_norm_emb -> /content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/mean_var_norm_emb.ckpt\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): classifier -> /content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/classifier.ckpt\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): label_encoder -> /content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/label_encoder.ckpt\n",
      "DEBUG:speechbrain.dataio.encoder:Loaded categorical encoding from /content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/label_encoder.ckpt\n",
      "INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Using symlink found at '/content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/hyperparams.yaml'\n",
      "INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/spkrec-xvect-voxceleb' if not cached\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Collecting files (or symlinks) for pretraining in tmp_model.\n",
      "INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Using symlink found at '/content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/embedding_model.ckpt'\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"embedding_model\"] = /content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/embedding_model.ckpt\n",
      "INFO:speechbrain.utils.fetching:Fetch mean_var_norm_emb.ckpt: Using symlink found at '/content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/mean_var_norm_emb.ckpt'\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"mean_var_norm_emb\"] = /content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/mean_var_norm_emb.ckpt\n",
      "INFO:speechbrain.utils.fetching:Fetch classifier.ckpt: Using symlink found at '/content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/classifier.ckpt'\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"classifier\"] = /content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/classifier.ckpt\n",
      "INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Using symlink found at '/content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/label_encoder.ckpt'\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"label_encoder\"] = /content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/label_encoder.ckpt\n",
      "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): embedding_model -> /content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/embedding_model.ckpt\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): mean_var_norm_emb -> /content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/mean_var_norm_emb.ckpt\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): classifier -> /content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/classifier.ckpt\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): label_encoder -> /content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/label_encoder.ckpt\n",
      "DEBUG:speechbrain.dataio.encoder:Loaded categorical encoding from /content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/label_encoder.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment run...\n",
      "Running: Sample sample_1 | Ref Duration: 5.0s\n",
      "  -> Similarity: 0.9641 | Text match len: 23/23\n",
      "Running: Sample sample_1 | Ref Duration: 10.0s\n",
      "  -> Similarity: 0.9636 | Text match len: 21/23\n",
      "Running: Sample sample_1 | Ref Duration: 15.0s\n",
      "  -> Similarity: 0.9664 | Text match len: 24/23\n",
      "Running: Sample sample_1 | Ref Duration: 20.0s\n",
      "  -> Similarity: 0.9633 | Text match len: 18/23\n",
      "Running: Sample sample_1 | Ref Duration: 30.0s\n",
      "  -> Similarity: 0.9627 | Text match len: 26/23\n",
      "Running: Sample sample_2 | Ref Duration: 5.0s\n",
      "  -> Similarity: 0.9420 | Text match len: 53/52\n",
      "Running: Sample sample_2 | Ref Duration: 10.0s\n",
      "  -> Similarity: 0.9433 | Text match len: 56/52\n",
      "Running: Sample sample_2 | Ref Duration: 15.0s\n",
      "  -> Similarity: 0.9380 | Text match len: 53/52\n",
      "Running: Sample sample_2 | Ref Duration: 20.0s\n",
      "  -> Similarity: 0.9314 | Text match len: 54/52\n",
      "Running: Sample sample_2 | Ref Duration: 30.0s\n",
      "  -> Similarity: 0.9425 | Text match len: 51/52\n",
      "Running: Sample sample_3 | Ref Duration: 5.0s\n",
      "  -> Similarity: 0.9415 | Text match len: 13/39\n",
      "Running: Sample sample_3 | Ref Duration: 10.0s\n",
      "  -> Similarity: 0.9423 | Text match len: 26/39\n",
      "Running: Sample sample_3 | Ref Duration: 15.0s\n",
      "  -> Similarity: 0.9437 | Text match len: 26/39\n",
      "Running: Sample sample_3 | Ref Duration: 20.0s\n",
      "  -> Similarity: 0.9420 | Text match len: 26/39\n",
      "Running: Sample sample_3 | Ref Duration: 30.0s\n",
      "  -> Similarity: 0.9440 | Text match len: 25/39\n",
      "Running: Sample sample_4 | Ref Duration: 5.0s\n",
      "  -> Similarity: 0.9204 | Text match len: 4/18\n",
      "Running: Sample sample_4 | Ref Duration: 10.0s\n",
      "  -> Similarity: 0.9353 | Text match len: 23/18\n",
      "Running: Sample sample_4 | Ref Duration: 15.0s\n",
      "  -> Similarity: 0.9190 | Text match len: 12/18\n",
      "Running: Sample sample_4 | Ref Duration: 20.0s\n",
      "  -> Similarity: 0.9248 | Text match len: 18/18\n",
      "Running: Sample sample_4 | Ref Duration: 30.0s\n",
      "  -> Similarity: 0.9210 | Text match len: 17/18\n",
      "Running: Sample sample_5 | Ref Duration: 5.0s\n",
      "  -> Similarity: 0.9490 | Text match len: 13/31\n",
      "Running: Sample sample_5 | Ref Duration: 10.0s\n",
      "  -> Similarity: 0.9671 | Text match len: 27/31\n",
      "Running: Sample sample_5 | Ref Duration: 15.0s\n",
      "  -> Similarity: 0.9652 | Text match len: 71/31\n",
      "Running: Sample sample_5 | Ref Duration: 20.0s\n",
      "  -> Similarity: 0.9696 | Text match len: 21/31\n",
      "Running: Sample sample_5 | Ref Duration: 30.0s\n",
      "  -> Similarity: 0.9661 | Text match len: 28/31\n"
     ]
    }
   ],
   "source": [
    "runner = ExperimentRunner()\n",
    "runner.run(manifest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analyze Results\n",
    "Save and inspect the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to experiment_results.csv\n",
      "\n",
      "Average Similarity Scores by Duration:\n",
      "duration\n",
      "5.0     0.943411\n",
      "10.0    0.950323\n",
      "15.0    0.946460\n",
      "20.0    0.946204\n",
      "30.0    0.947252\n",
      "Name: similarity_score, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-425c2853-346d-40fe-abd6-db80b8a76374\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>original_text</th>\n",
       "      <th>target_text</th>\n",
       "      <th>transcribed_text</th>\n",
       "      <th>output_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample_1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.964087</td>\n",
       "      <td>and in that way the months passed</td>\n",
       "      <td>y así pasaron los meses</td>\n",
       "      <td>Dis Pazar and los grace</td>\n",
       "      <td>experiment_data/sample_1/out_sample_1_5.0s.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample_1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.963644</td>\n",
       "      <td>and in that way the months passed</td>\n",
       "      <td>y así pasaron los meses</td>\n",
       "      <td>by s pésern los mises</td>\n",
       "      <td>experiment_data/sample_1/out_sample_1_10.0s.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample_1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.966439</td>\n",
       "      <td>and in that way the months passed</td>\n",
       "      <td>y así pasaron los meses</td>\n",
       "      <td>SKS Pessarón Las Mises の</td>\n",
       "      <td>experiment_data/sample_1/out_sample_1_15.0s.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample_1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.963255</td>\n",
       "      <td>and in that way the months passed</td>\n",
       "      <td>y así pasaron los meses</td>\n",
       "      <td>Pesarón laws mises</td>\n",
       "      <td>experiment_data/sample_1/out_sample_1_20.0s.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample_1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.962717</td>\n",
       "      <td>and in that way the months passed</td>\n",
       "      <td>y así pasaron los meses</td>\n",
       "      <td>disemple tense se los min化</td>\n",
       "      <td>experiment_data/sample_1/out_sample_1_30.0s.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sample_2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.942031</td>\n",
       "      <td>about time one of you lunkheads said it</td>\n",
       "      <td>Ya era hora de que lo dijera uno de ustedes, t...</td>\n",
       "      <td>Ya era hora de crulo de Gerr, a no de Estids, ...</td>\n",
       "      <td>experiment_data/sample_2/out_sample_2_5.0s.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sample_2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.943264</td>\n",
       "      <td>about time one of you lunkheads said it</td>\n",
       "      <td>Ya era hora de que lo dijera uno de ustedes, t...</td>\n",
       "      <td>Ya era horror de culo de Dijera, a no de Estid...</td>\n",
       "      <td>experiment_data/sample_2/out_sample_2_10.0s.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sample_2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.937969</td>\n",
       "      <td>about time one of you lunkheads said it</td>\n",
       "      <td>Ya era hora de que lo dijera uno de ustedes, t...</td>\n",
       "      <td>Ya era horror de Kilo Dijera, a no de Estid's ...</td>\n",
       "      <td>experiment_data/sample_2/out_sample_2_15.0s.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sample_2</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.931402</td>\n",
       "      <td>about time one of you lunkheads said it</td>\n",
       "      <td>Ya era hora de que lo dijera uno de ustedes, t...</td>\n",
       "      <td>Ya era hora de culo de Dijera, a no de Estid's...</td>\n",
       "      <td>experiment_data/sample_2/out_sample_2_20.0s.wav</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>sample_2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.942475</td>\n",
       "      <td>about time one of you lunkheads said it</td>\n",
       "      <td>Ya era hora de que lo dijera uno de ustedes, t...</td>\n",
       "      <td>y a Erohora de Culo de Dura, Anodia Steeds, Po...</td>\n",
       "      <td>experiment_data/sample_2/out_sample_2_30.0s.wav</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-425c2853-346d-40fe-abd6-db80b8a76374')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-425c2853-346d-40fe-abd6-db80b8a76374 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-425c2853-346d-40fe-abd6-db80b8a76374');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "  sample_id  duration  similarity_score  \\\n",
       "0  sample_1       5.0          0.964087   \n",
       "1  sample_1      10.0          0.963644   \n",
       "2  sample_1      15.0          0.966439   \n",
       "3  sample_1      20.0          0.963255   \n",
       "4  sample_1      30.0          0.962717   \n",
       "5  sample_2       5.0          0.942031   \n",
       "6  sample_2      10.0          0.943264   \n",
       "7  sample_2      15.0          0.937969   \n",
       "8  sample_2      20.0          0.931402   \n",
       "9  sample_2      30.0          0.942475   \n",
       "\n",
       "                             original_text  \\\n",
       "0        and in that way the months passed   \n",
       "1        and in that way the months passed   \n",
       "2        and in that way the months passed   \n",
       "3        and in that way the months passed   \n",
       "4        and in that way the months passed   \n",
       "5  about time one of you lunkheads said it   \n",
       "6  about time one of you lunkheads said it   \n",
       "7  about time one of you lunkheads said it   \n",
       "8  about time one of you lunkheads said it   \n",
       "9  about time one of you lunkheads said it   \n",
       "\n",
       "                                         target_text  \\\n",
       "0                            y así pasaron los meses   \n",
       "1                            y así pasaron los meses   \n",
       "2                            y así pasaron los meses   \n",
       "3                            y así pasaron los meses   \n",
       "4                            y así pasaron los meses   \n",
       "5  Ya era hora de que lo dijera uno de ustedes, t...   \n",
       "6  Ya era hora de que lo dijera uno de ustedes, t...   \n",
       "7  Ya era hora de que lo dijera uno de ustedes, t...   \n",
       "8  Ya era hora de que lo dijera uno de ustedes, t...   \n",
       "9  Ya era hora de que lo dijera uno de ustedes, t...   \n",
       "\n",
       "                                    transcribed_text  \\\n",
       "0                            Dis Pazar and los grace   \n",
       "1                              by s pésern los mises   \n",
       "2                           SKS Pessarón Las Mises の   \n",
       "3                                 Pesarón laws mises   \n",
       "4                         disemple tense se los min化   \n",
       "5  Ya era hora de crulo de Gerr, a no de Estids, ...   \n",
       "6  Ya era horror de culo de Dijera, a no de Estid...   \n",
       "7  Ya era horror de Kilo Dijera, a no de Estid's ...   \n",
       "8  Ya era hora de culo de Dijera, a no de Estid's...   \n",
       "9  y a Erohora de Culo de Dura, Anodia Steeds, Po...   \n",
       "\n",
       "                                       output_path  \n",
       "0   experiment_data/sample_1/out_sample_1_5.0s.wav  \n",
       "1  experiment_data/sample_1/out_sample_1_10.0s.wav  \n",
       "2  experiment_data/sample_1/out_sample_1_15.0s.wav  \n",
       "3  experiment_data/sample_1/out_sample_1_20.0s.wav  \n",
       "4  experiment_data/sample_1/out_sample_1_30.0s.wav  \n",
       "5   experiment_data/sample_2/out_sample_2_5.0s.wav  \n",
       "6  experiment_data/sample_2/out_sample_2_10.0s.wav  \n",
       "7  experiment_data/sample_2/out_sample_2_15.0s.wav  \n",
       "8  experiment_data/sample_2/out_sample_2_20.0s.wav  \n",
       "9  experiment_data/sample_2/out_sample_2_30.0s.wav  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runner.save_results(\"experiment_results.csv\")\n",
    "\n",
    "import pandas as pd\n",
    "results_df = pd.read_csv(\"experiment_results.csv\")\n",
    "\n",
    "# Display average similarity score per duration\n",
    "print(\"\\nAverage Similarity Scores by Duration:\")\n",
    "print(results_df.groupby(\"duration\")[\"similarity_score\"].mean())\n",
    "\n",
    "results_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Real-World Demo\n",
    "Record your own voice, translate it, and check the similarity score.\n",
    "NOTE: This requires a microphone. If running on a remote Colab kernel without audio forwarding, this might not work directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-World Test\n",
    "from asr_service import ASRService\n",
    "from translation_service import TranslationService\n",
    "from tts_service import TTSService\n",
    "from embedding_service import EmbeddingService\n",
    "from enums import Language\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def run_live_demo(duration=10):\n",
    "    print(f\"--- Live Demo (Enrollment: {duration}s) ---\")\n",
    "    \n",
    "    # Initialize services\n",
    "    asr = ASRService()\n",
    "    translator = TranslationService()\n",
    "    tts = TTSService()\n",
    "    embedder = EmbeddingService()\n",
    "    \n",
    "    # 1. Record Input\n",
    "    try:\n",
    "        # Step 1: Listen and Transcribe\n",
    "        print(\"\\nRecording... (speak now)\")\n",
    "        english_text, source_audio_path = asr.listen_transcribe(duration=5)\n",
    "        print(f\"Transcribed: {english_text}\")\n",
    "        \n",
    "        # Step 2: Record Enrollment (Reference)\n",
    "        # Ideally we use the same audio if it's long enough, but let's record a dedicated style clip\n",
    "        # input(\"Press Enter to record style enrollment (speak clearly)...\")\n",
    "        # ref_path = asr.record_audio(duration=duration, file_path=\"demo_ref.wav\")\n",
    "        \n",
    "        # Simpler: Just use the input audio itself as reference (Zero-Shot on self)\n",
    "        ref_path = source_audio_path\n",
    "\n",
    "        # 2. Translate\n",
    "        spanish_text = translator.translate(english_text, target_language=Language.SPANISH)\n",
    "        print(f\"Translated: {spanish_text}\")\n",
    "\n",
    "        # 3. Synthesize\n",
    "        output_path = \"demo_output.wav\"\n",
    "        tts.synthesize(spanish_text, output_path, ref_path)\n",
    "        print(f\"Synthesized audio saved to {output_path}\")\n",
    "\n",
    "        # 4. Evaluate Similarity\n",
    "        gt_embedding = embedder.extract_embedding(ref_path)\n",
    "        out_embedding = embedder.extract_embedding(output_path)\n",
    "        \n",
    "        if gt_embedding.dim() == 1: gt_embedding = gt_embedding.unsqueeze(0)\n",
    "        if out_embedding.dim() == 1: out_embedding = out_embedding.unsqueeze(0)\n",
    "            \n",
    "        score = F.cosine_similarity(gt_embedding, out_embedding).item()\n",
    "        print(f\"Speaker Similarity Score: {score:.4f}\")\n",
    "        \n",
    "        # Playback (if in Colab/Jupyter)\n",
    "        from IPython.display import Audio, display\n",
    "        print(\"Original:\")\n",
    "        display(Audio(source_audio_path))\n",
    "        print(\"Synthesized (Spanish):\")\n",
    "        display(Audio(output_path))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during demo: {e}\")\n",
    "        print(\"Note: Microphone recording might fail on remote servers without audio forwarding.\")\n",
    "\n",
    "# run_live_demo(duration=10)\n",
    "# To run this on Colab, you'd typically need a Javascript helper to record audio from the browser,\n",
    "# as 'sounddevice' tries to access the server's mic (which doesn't exist).\n",
    "# For now, this code works if running locally."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
