{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style-Preserving Speech-to-Speech Translation Experiment\n",
    "\n",
    "This notebook runs the experiment to determine the minimal duration of speaker embeddings required to effectively clone a speaker's voice across languages.\n",
    "\n",
    "## 1. Setup Environment\n",
    "Install necessary dependencies if running on Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only if needed, clear all files except experiment.ipynb\n",
    "# This command will remove all files and folders in the current directory except \"experiment.ipynb\"\n",
    "import os\n",
    "\n",
    "for fname in os.listdir():\n",
    "    if fname != \"experiment.ipynb\":\n",
    "        if os.path.isdir(fname):\n",
    "            import shutil\n",
    "            shutil.rmtree(fname)\n",
    "        else:\n",
    "            os.remove(fname)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'CS479-SpeakerEmbeddings'...\n",
      "remote: Enumerating objects: 44, done.\u001b[K\n",
      "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
      "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
      "remote: Total 44 (delta 10), reused 44 (delta 10), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (44/44), 564.29 KiB | 8.96 MiB/s, done.\n",
      "Resolving deltas: 100% (10/10), done.\n",
      "Reloaded common_voice_dataset\n",
      "Reloaded setup_experiment\n",
      "Reloaded run_experiment\n",
      "Reloaded asr_service\n",
      "Reloaded translation_service\n",
      "Reloaded tts_service\n",
      "Reloaded embedding_service\n",
      "Reloaded synthetic_data_service\n",
      "Reloaded enums\n"
     ]
    }
   ],
   "source": [
    "# Cell to refresh code from GitHub\n",
    "import os\n",
    "\n",
    "# Navigate to the repo directory\n",
    "if os.path.exists(\"CS479-SpeakerEmbeddings\"):\n",
    "    os.chdir(\"CS479-SpeakerEmbeddings\")\n",
    "    !git pull\n",
    "else:\n",
    "    !git clone https://github.com/NathanAsayDong/CS479-SpeakerEmbeddings.git\n",
    "    os.chdir(\"CS479-SpeakerEmbeddings\")\n",
    "\n",
    "# Optional: Reload modules if you've already imported them\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "# List of your custom modules to reload\n",
    "modules_to_reload = [\n",
    "    \"common_voice_dataset\",\n",
    "    \"setup_experiment\",\n",
    "    \"run_experiment\",\n",
    "    \"asr_service\",\n",
    "    \"translation_service\",\n",
    "    \"tts_service\",\n",
    "    \"embedding_service\",\n",
    "    \"synthetic_data_service\",\n",
    "    \"enums\"\n",
    "]\n",
    "\n",
    "for module_name in modules_to_reload:\n",
    "    if module_name in sys.modules:\n",
    "        importlib.reload(sys.modules[module_name])\n",
    "        print(f\"Reloaded {module_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'CS479-SpeakerEmbeddings'...\n",
      "remote: Enumerating objects: 44, done.\u001b[K\n",
      "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
      "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
      "remote: Total 44 (delta 10), reused 44 (delta 10), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (44/44), 564.29 KiB | 13.76 MiB/s, done.\n",
      "Resolving deltas: 100% (10/10), done.\n",
      "/content/CS479-SpeakerEmbeddings\n",
      "asr_service.py\t\t peoples_speech_dataset.py  setup_experiment.py\n",
      "common_voice_dataset.py  ProjectOutline.pdf\t    synthetic_data_service.py\n",
      "embedding_service.py\t __pycache__\t\t    tmp_model\n",
      "enums.py\t\t readMe\t\t\t    translation_service.py\n",
      "experiment.ipynb\t requirements.txt\t    tts_service.py\n",
      "libri_speech_dataset.py  run_experiment.py\n",
      "main.py\t\t\t Samples\n"
     ]
    }
   ],
   "source": [
    "# For refreshing GitHub repo in Colab: remove old directory and re-clone\n",
    "import shutil, os\n",
    "#cd out of the current directory\n",
    "%cd ..\n",
    "!ls\n",
    "# repo_dir = \"CS479-SpeakerEmbeddings\"\n",
    "# if os.path.exists(repo_dir):\n",
    "#     shutil.rmtree(repo_dir)\n",
    "# !git clone https://github.com/NathanAsayDong/CS479-SpeakerEmbeddings.git\n",
    "# %cd CS479-SpeakerEmbeddings\n",
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sounddevice in /usr/local/lib/python3.12/dist-packages (0.5.3)\n",
      "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.12/dist-packages (from sounddevice) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from CFFI>=1.0->sounddevice) (2.23)\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "libportaudio2 is already the newest version (19.6.0-1.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "# !pip install torch transformers speechbrain soundfile librosa openai-whisper accelerate sentencepiece pydantic torchcodec datasets kagglehub[pandas-datasets]\n",
    "# !pip install sounddevice\n",
    "# !sudo apt-get install libportaudio2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Modules\n",
    "Import the experiment setup and runner classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add current directory to path if needed\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from enums import Language\n",
    "from setup_experiment import ExperimentSetup\n",
    "from run_experiment import ExperimentRunner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configure Experiment\n",
    "Define the parameters for the experiment: source/target languages and reference durations to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_LANG = Language.ENGLISH\n",
    "TARGET_LANG = Language.SPANISH\n",
    "DURATIONS = [5.0, 10.0, 15.0, 20.0, 30.0]\n",
    "NUM_SPEAKERS = 5 # Number of unique speakers to test\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare Data\n",
    "This step:\n",
    "1. Downloads/Loads Common Voice dataset via KaggleHub.\n",
    "2. Selects `NUM_SPEAKERS` with sufficient data.\n",
    "3. Creates concatenated reference audio files for each duration.\n",
    "4. Generates a manifest for the experiment run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/CS479-SpeakerEmbeddings\n",
      "asr_service.py\t\t libri_speech_dataset.py    run_experiment.py\n",
      "common_voice_dataset.py  main.py\t\t    Samples\n",
      "CS479-SpeakerEmbeddings  peoples_speech_dataset.py  setup_experiment.py\n",
      "embedding_service.py\t ProjectOutline.pdf\t    synthetic_data_service.py\n",
      "enums.py\t\t __pycache__\t\t    tmp_model\n",
      "experiment_data\t\t readMe\t\t\t    translation_service.py\n",
      "experiment.ipynb\t requirements.txt\t    tts_service.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing experiment data for 5 speakers...\n",
      "Loading Common Voice dataset for language 'en'...\n",
      "Using Colab cache for faster access to the 'common-voice' dataset.\n",
      "Dataset path: /kaggle/input/common-voice\n",
      "Searching for language 'en' in /kaggle/input/common-voice\n",
      "Could not find exact language directory. Listing root directories for debugging:\n",
      " - cv-valid-test\n",
      " - cv-invalid\n",
      " - cv-other-test\n",
      " - cv-other-train.csv\n",
      " - cv-invalid.csv\n",
      " - cv-valid-dev.csv\n",
      " - README.txt\n",
      " - cv-valid-train.csv\n",
      " - LICENSE.txt\n",
      " - cv-valid-test.csv\n",
      " - cv-valid-dev\n",
      " - cv-other-dev.csv\n",
      " - cv-other-dev\n",
      " - cv-valid-train\n",
      " - cv-other-train\n",
      " - cv-other-test.csv\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Could not find directory for language 'en' in /kaggle/input/common-voice",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-869352715.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Prepare the manifest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmanifest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_speakers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_SPEAKERS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Manifest ready with {len(manifest)} speakers.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/setup_experiment.py\u001b[0m in \u001b[0;36mprepare_data\u001b[0;34m(self, num_speakers)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# We need a language code for Common Voice (e.g., 'en' for English)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mcv_lang_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"en\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_language\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mLanguage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mENGLISH\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"es\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCommonVoiceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv_lang_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"dev\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Using dev for faster loading/experimentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;31m# 2. Select Speakers with Enough Data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/common_voice_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, language_code, split)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_language_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m              \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Could not find directory for language '{language_code}' in {self.dataset_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtsv_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlang_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{split}.tsv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Could not find directory for language 'en' in /kaggle/input/common-voice"
     ]
    }
   ],
   "source": [
    "setup = ExperimentSetup(\n",
    "    source_language=SOURCE_LANG,\n",
    "    target_language=TARGET_LANG,\n",
    "    reference_durations=DURATIONS,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "# Prepare the manifest\n",
    "manifest = setup.prepare_data(num_speakers=NUM_SPEAKERS)\n",
    "\n",
    "print(f\"Manifest ready with {len(manifest)} speakers.\")\n",
    "print(\"Sample Item:\", manifest[0] if manifest else \"No data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Experiment\n",
    "Execute the pipeline for each speaker and duration:\n",
    "1. Extract ground truth embedding (original speaker).\n",
    "2. Translate source text to Spanish.\n",
    "3. Synthesize Spanish speech using the reference audio (5s, 10s, etc.) for style.\n",
    "4. Compute Cosine Similarity between ground truth and output embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = ExperimentRunner()\n",
    "runner.run(manifest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analyze Results\n",
    "Save and inspect the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.save_results(\"experiment_results.csv\")\n",
    "\n",
    "import pandas as pd\n",
    "results_df = pd.read_csv(\"experiment_results.csv\")\n",
    "\n",
    "# Display average similarity score per duration\n",
    "print(\"\\nAverage Similarity Scores by Duration:\")\n",
    "print(results_df.groupby(\"duration\")[\"similarity_score\"].mean())\n",
    "\n",
    "results_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
