{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style-Preserving Speech-to-Speech Translation Experiment\n",
    "\n",
    "This notebook runs the experiment to determine the minimal duration of speaker embeddings required to effectively clone a speaker's voice across languages.\n",
    "\n",
    "## 1. Setup Environment\n",
    "Install necessary dependencies if running on Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only if needed, clear all files except experiment.ipynb\n",
    "# This command will remove all files and folders in the current directory except \"experiment.ipynb\"\n",
    "import os\n",
    "\n",
    "for fname in os.listdir():\n",
    "    if fname != \"experiment.ipynb\":\n",
    "        if os.path.isdir(fname):\n",
    "            import shutil\n",
    "            shutil.rmtree(fname)\n",
    "        else:\n",
    "            os.remove(fname)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'CS479-SpeakerEmbeddings'...\n",
      "remote: Enumerating objects: 81, done.\u001b[K\n",
      "remote: Counting objects: 100% (81/81), done.\u001b[K\n",
      "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
      "remote: Total 81 (delta 39), reused 67 (delta 25), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (81/81), 600.20 KiB | 17.15 MiB/s, done.\n",
      "Resolving deltas: 100% (39/39), done.\n",
      "Reloaded common_voice_dataset\n",
      "Reloaded setup_experiment\n",
      "Reloaded run_experiment\n",
      "Reloaded asr_service\n",
      "Reloaded translation_service\n",
      "Reloaded tts_service\n",
      "Reloaded embedding_service\n",
      "Reloaded synthetic_data_service\n",
      "Reloaded enums\n"
     ]
    }
   ],
   "source": [
    "# Cell to refresh code from GitHub\n",
    "import os\n",
    "\n",
    "# Navigate to the repo directory\n",
    "if os.path.exists(\"CS479-SpeakerEmbeddings\"):\n",
    "    os.chdir(\"CS479-SpeakerEmbeddings\")\n",
    "    !git pull\n",
    "else:\n",
    "    !git clone https://github.com/NathanAsayDong/CS479-SpeakerEmbeddings.git\n",
    "    os.chdir(\"CS479-SpeakerEmbeddings\")\n",
    "\n",
    "# Optional: Reload modules if you've already imported them\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "# List of your custom modules to reload\n",
    "modules_to_reload = [\n",
    "    \"common_voice_dataset\",\n",
    "    \"setup_experiment\",\n",
    "    \"run_experiment\",\n",
    "    \"asr_service\",\n",
    "    \"translation_service\",\n",
    "    \"tts_service\",\n",
    "    \"embedding_service\",\n",
    "    \"synthetic_data_service\",\n",
    "    \"enums\"\n",
    "]\n",
    "\n",
    "for module_name in modules_to_reload:\n",
    "    if module_name in sys.modules:\n",
    "        importlib.reload(sys.modules[module_name])\n",
    "        print(f\"Reloaded {module_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# repo_dir = \"CS479-SpeakerEmbeddings\"\n",
    "# if os.path.exists(repo_dir):\n",
    "#     shutil.rmtree(repo_dir)\n",
    "# !git clone https://github.com/NathanAsayDong/CS479-SpeakerEmbeddings.git\n",
    "# %cd CS479-SpeakerEmbeddings\n",
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.2)\n",
      "Requirement already satisfied: speechbrain in /usr/local/lib/python3.12/dist-packages (1.0.3)\n",
      "Requirement already satisfied: soundfile in /usr/local/lib/python3.12/dist-packages (0.13.1)\n",
      "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
      "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.12/dist-packages (20250625)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (2.12.3)\n",
      "Requirement already satisfied: torchcodec in /usr/local/lib/python3.12/dist-packages (0.8.1)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
      "Requirement already satisfied: kagglehub[pandas-datasets] in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: hyperpyyaml in /usr/local/lib/python3.12/dist-packages (from speechbrain) (1.2.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from speechbrain) (1.5.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from speechbrain) (1.16.3)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (from speechbrain) (2.9.0+cu126)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile) (2.0.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa) (3.1.0)\n",
      "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.6.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.4.2)\n",
      "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.0.0)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.1.2)\n",
      "Requirement already satisfied: more-itertools in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (10.8.0)\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.12/dist-packages (from openai-whisper) (0.12.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.4.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile) (2.23)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (4.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.11.12)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: ruamel.yaml>=0.17.28 in /usr/local/lib/python3.12/dist-packages (from hyperpyyaml->speechbrain) (0.18.16)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.12/dist-packages (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain) (0.2.15)\n",
      "Requirement already satisfied: sounddevice in /usr/local/lib/python3.12/dist-packages (0.5.3)\n",
      "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.12/dist-packages (from sounddevice) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from CFFI>=1.0->sounddevice) (2.23)\n",
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "libportaudio2 is already the newest version (19.6.0-1.1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 41 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!pip install torch transformers speechbrain soundfile librosa openai-whisper accelerate sentencepiece pydantic torchcodec datasets kagglehub[pandas-datasets]\n",
    "!pip install sounddevice\n",
    "!sudo apt-get install libportaudio2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Modules\n",
    "Import the experiment setup and runner classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add current directory to path if needed\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from enums import Language\n",
    "from setup_experiment import ExperimentSetup\n",
    "from run_experiment import ExperimentRunner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Configure Experiment\n",
    "Define the parameters for the experiment: source/target languages and reference durations to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_LANG = Language.ENGLISH\n",
    "TARGET_LANG = Language.SPANISH\n",
    "DURATIONS = [5.0, 10.0, 15.0, 20.0, 30.0]\n",
    "NUM_SAMPLES_PER_DURATION = 5 # Number of unique speakers to test\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare Data\n",
    "This step:\n",
    "1. Downloads/Loads Common Voice dataset via KaggleHub.\n",
    "2. Selects `NUM_SPEAKERS` with sufficient data.\n",
    "3. Creates concatenated reference audio files for each duration.\n",
    "4. Generates a manifest for the experiment run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asr_service.py\t\t peoples_speech_dataset.py  setup_experiment.py\n",
      "common_voice_dataset.py  ProjectOutline.pdf\t    synthetic_data_service.py\n",
      "embedding_service.py\t __pycache__\t\t    tmp_model\n",
      "enums.py\t\t readMe\t\t\t    translation_service.py\n",
      "experiment.ipynb\t requirements.txt\t    tts_service.py\n",
      "libri_speech_dataset.py  run_experiment.py\n",
      "main.py\t\t\t Samples\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing experiment data: 5 samples for each of [5.0, 10.0, 15.0, 20.0, 30.0]s durations...\n",
      "Loading Common Voice dataset for language 'en'...\n",
      "Using Colab cache for faster access to the 'common-voice' dataset.\n",
      "Dataset path: /kaggle/input/common-voice\n",
      "Searching for language 'en' in /kaggle/input/common-voice\n",
      "Found flattened dataset structure at /kaggle/input/common-voice\n",
      "Loaded 4076 records for en/dev\n",
      "Columns: ['filename', 'text', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'duration', 'path', 'sentence']\n",
      "Warning: 'client_id' not found in metadata. Using dummy IDs or skipping speaker grouping.\n",
      "Manifest ready with 25 speakers.\n",
      "Sample Item: {'sample_id': 'sample_1', 'test_input_path': '/kaggle/input/common-voice/cv-valid-dev/cv-valid-dev/sample-001749.mp3', 'test_input_text': 'and in that way the months passed', 'reference_path': 'experiment_data/sample_1/ref_5s.wav', 'target_duration': 5.0}\n"
     ]
    }
   ],
   "source": [
    "setup = ExperimentSetup(\n",
    "    source_language=SOURCE_LANG,\n",
    "    target_language=TARGET_LANG,\n",
    "    reference_durations=DURATIONS,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "# Prepare the manifest\n",
    "manifest = setup.prepare_data(num_samples_per_duration=NUM_SAMPLES_PER_DURATION)\n",
    "\n",
    "print(f\"Manifest ready with {len(manifest)} speakers.\")\n",
    "print(\"Sample Item:\", manifest[0] if manifest else \"No data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Experiment\n",
    "Execute the pipeline for each speaker and duration:\n",
    "1. Extract ground truth embedding (original speaker).\n",
    "2. Translate source text to Spanish.\n",
    "3. Synthesize Spanish speech using the reference audio (5s, 10s, etc.) for style.\n",
    "4. Compute Cosine Similarity between ground truth and output embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Fetching from HuggingFace Hub 'speechbrain/spkrec-xvect-voxceleb' if not cached\n",
      "DEBUG:speechbrain.utils.fetching:Fetch: Local file found, creating symlink '/root/.cache/huggingface/hub/models--speechbrain--spkrec-xvect-voxceleb/snapshots/56895a2df401be4150a159f3a1c653f00051d477/hyperparams.yaml' -> '/content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/hyperparams.yaml'\n",
      "INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/spkrec-xvect-voxceleb' if not cached\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Collecting files (or symlinks) for pretraining in tmp_model.\n",
      "INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-xvect-voxceleb' if not cached\n",
      "DEBUG:speechbrain.utils.fetching:Fetch: Local file found, creating symlink '/root/.cache/huggingface/hub/models--speechbrain--spkrec-xvect-voxceleb/snapshots/56895a2df401be4150a159f3a1c653f00051d477/embedding_model.ckpt' -> '/content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/embedding_model.ckpt'\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"embedding_model\"] = /content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/embedding_model.ckpt\n",
      "INFO:speechbrain.utils.fetching:Fetch mean_var_norm_emb.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-xvect-voxceleb' if not cached\n",
      "DEBUG:speechbrain.utils.fetching:Fetch: Local file found, creating symlink '/root/.cache/huggingface/hub/models--speechbrain--spkrec-xvect-voxceleb/snapshots/56895a2df401be4150a159f3a1c653f00051d477/mean_var_norm_emb.ckpt' -> '/content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/mean_var_norm_emb.ckpt'\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"mean_var_norm_emb\"] = /content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/mean_var_norm_emb.ckpt\n",
      "INFO:speechbrain.utils.fetching:Fetch classifier.ckpt: Fetching from HuggingFace Hub 'speechbrain/spkrec-xvect-voxceleb' if not cached\n",
      "DEBUG:speechbrain.utils.fetching:Fetch: Local file found, creating symlink '/root/.cache/huggingface/hub/models--speechbrain--spkrec-xvect-voxceleb/snapshots/56895a2df401be4150a159f3a1c653f00051d477/classifier.ckpt' -> '/content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/classifier.ckpt'\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"classifier\"] = /content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/classifier.ckpt\n",
      "INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Fetching from HuggingFace Hub 'speechbrain/spkrec-xvect-voxceleb' if not cached\n",
      "DEBUG:speechbrain.utils.fetching:Fetch: Local file found, creating symlink '/root/.cache/huggingface/hub/models--speechbrain--spkrec-xvect-voxceleb/snapshots/56895a2df401be4150a159f3a1c653f00051d477/label_encoder.txt' -> '/content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/label_encoder.ckpt'\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"label_encoder\"] = /content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/label_encoder.ckpt\n",
      "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): embedding_model -> /content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/embedding_model.ckpt\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): mean_var_norm_emb -> /content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/mean_var_norm_emb.ckpt\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): classifier -> /content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/classifier.ckpt\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): label_encoder -> /content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/label_encoder.ckpt\n",
      "DEBUG:speechbrain.dataio.encoder:Loaded categorical encoding from /content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/label_encoder.ckpt\n",
      "INFO:speechbrain.utils.fetching:Fetch hyperparams.yaml: Using symlink found at '/content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/hyperparams.yaml'\n",
      "INFO:speechbrain.utils.fetching:Fetch custom.py: Fetching from HuggingFace Hub 'speechbrain/spkrec-xvect-voxceleb' if not cached\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Collecting files (or symlinks) for pretraining in tmp_model.\n",
      "INFO:speechbrain.utils.fetching:Fetch embedding_model.ckpt: Using symlink found at '/content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/embedding_model.ckpt'\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"embedding_model\"] = /content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/embedding_model.ckpt\n",
      "INFO:speechbrain.utils.fetching:Fetch mean_var_norm_emb.ckpt: Using symlink found at '/content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/mean_var_norm_emb.ckpt'\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"mean_var_norm_emb\"] = /content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/mean_var_norm_emb.ckpt\n",
      "INFO:speechbrain.utils.fetching:Fetch classifier.ckpt: Using symlink found at '/content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/classifier.ckpt'\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"classifier\"] = /content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/classifier.ckpt\n",
      "INFO:speechbrain.utils.fetching:Fetch label_encoder.txt: Using symlink found at '/content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/label_encoder.ckpt'\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Set local path in self.paths[\"label_encoder\"] = /content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/label_encoder.ckpt\n",
      "INFO:speechbrain.utils.parameter_transfer:Loading pretrained files for: embedding_model, mean_var_norm_emb, classifier, label_encoder\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): embedding_model -> /content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/embedding_model.ckpt\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): mean_var_norm_emb -> /content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/mean_var_norm_emb.ckpt\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): classifier -> /content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/classifier.ckpt\n",
      "DEBUG:speechbrain.utils.parameter_transfer:Redirecting (loading from local path): label_encoder -> /content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/label_encoder.ckpt\n",
      "DEBUG:speechbrain.dataio.encoder:Loaded categorical encoding from /content/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/CS479-SpeakerEmbeddings/tmp_model/label_encoder.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment run...\n",
      "Running: Sample sample_1 | Ref Duration: 5.0s\n",
      "  -> Error: cannot access local variable 'transcribed_spanish' where it is not associated with a value\n",
      "Running: Sample sample_1 | Ref Duration: 10.0s\n",
      "  -> Error: cannot access local variable 'transcribed_spanish' where it is not associated with a value\n",
      "Running: Sample sample_1 | Ref Duration: 15.0s\n",
      "  -> Error: cannot access local variable 'transcribed_spanish' where it is not associated with a value\n",
      "Running: Sample sample_1 | Ref Duration: 20.0s\n",
      "  -> Error: cannot access local variable 'transcribed_spanish' where it is not associated with a value\n",
      "Running: Sample sample_1 | Ref Duration: 30.0s\n",
      "  -> Error: cannot access local variable 'transcribed_spanish' where it is not associated with a value\n",
      "Running: Sample sample_2 | Ref Duration: 5.0s\n",
      "  -> Error: cannot access local variable 'transcribed_spanish' where it is not associated with a value\n",
      "Running: Sample sample_2 | Ref Duration: 10.0s\n",
      "  -> Error: cannot access local variable 'transcribed_spanish' where it is not associated with a value\n",
      "Running: Sample sample_2 | Ref Duration: 15.0s\n",
      "  -> Error: cannot access local variable 'transcribed_spanish' where it is not associated with a value\n",
      "Running: Sample sample_2 | Ref Duration: 20.0s\n",
      "  -> Error: cannot access local variable 'transcribed_spanish' where it is not associated with a value\n",
      "Running: Sample sample_2 | Ref Duration: 30.0s\n",
      "  -> Error: cannot access local variable 'transcribed_spanish' where it is not associated with a value\n",
      "Running: Sample sample_3 | Ref Duration: 5.0s\n",
      "  -> Error: cannot access local variable 'transcribed_spanish' where it is not associated with a value\n",
      "Running: Sample sample_3 | Ref Duration: 10.0s\n",
      "  -> Error: cannot access local variable 'transcribed_spanish' where it is not associated with a value\n",
      "Running: Sample sample_3 | Ref Duration: 15.0s\n",
      "  -> Error: cannot access local variable 'transcribed_spanish' where it is not associated with a value\n",
      "Running: Sample sample_3 | Ref Duration: 20.0s\n",
      "  -> Error: cannot access local variable 'transcribed_spanish' where it is not associated with a value\n",
      "Running: Sample sample_3 | Ref Duration: 30.0s\n",
      "  -> Error: cannot access local variable 'transcribed_spanish' where it is not associated with a value\n",
      "Running: Sample sample_4 | Ref Duration: 5.0s\n",
      "  -> Error: cannot access local variable 'transcribed_spanish' where it is not associated with a value\n",
      "Running: Sample sample_4 | Ref Duration: 10.0s\n",
      "  -> Error: cannot access local variable 'transcribed_spanish' where it is not associated with a value\n",
      "Running: Sample sample_4 | Ref Duration: 15.0s\n",
      "  -> Error: cannot access local variable 'transcribed_spanish' where it is not associated with a value\n",
      "Running: Sample sample_4 | Ref Duration: 20.0s\n",
      "  -> Error: cannot access local variable 'transcribed_spanish' where it is not associated with a value\n",
      "Running: Sample sample_4 | Ref Duration: 30.0s\n",
      "  -> Error: cannot access local variable 'transcribed_spanish' where it is not associated with a value\n",
      "Running: Sample sample_5 | Ref Duration: 5.0s\n",
      "  -> Error: cannot access local variable 'transcribed_spanish' where it is not associated with a value\n",
      "Running: Sample sample_5 | Ref Duration: 10.0s\n",
      "  -> Error: cannot access local variable 'transcribed_spanish' where it is not associated with a value\n",
      "Running: Sample sample_5 | Ref Duration: 15.0s\n",
      "  -> Error: cannot access local variable 'transcribed_spanish' where it is not associated with a value\n",
      "Running: Sample sample_5 | Ref Duration: 20.0s\n",
      "  -> Error: cannot access local variable 'transcribed_spanish' where it is not associated with a value\n",
      "Running: Sample sample_5 | Ref Duration: 30.0s\n",
      "  -> Error: cannot access local variable 'transcribed_spanish' where it is not associated with a value\n"
     ]
    }
   ],
   "source": [
    "runner = ExperimentRunner()\n",
    "runner.run(manifest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analyze Results\n",
    "Save and inspect the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to experiment_results.csv\n"
     ]
    },
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3373454240.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresults_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"experiment_results.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Display average similarity score per duration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1897\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1898\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1899\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;31m# Fail here loudly instead of in cython after reading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pyarrow\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "runner.save_results(\"experiment_results.csv\")\n",
    "\n",
    "import pandas as pd\n",
    "results_df = pd.read_csv(\"experiment_results.csv\")\n",
    "\n",
    "# Display average similarity score per duration\n",
    "print(\"\\nAverage Similarity Scores by Duration:\")\n",
    "print(results_df.groupby(\"duration\")[\"similarity_score\"].mean())\n",
    "\n",
    "results_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Real-World Demo\n",
    "Record your own voice, translate it, and check the similarity score.\n",
    "NOTE: This requires a microphone. If running on a remote Colab kernel without audio forwarding, this might not work directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-World Test\n",
    "from asr_service import ASRService\n",
    "from translation_service import TranslationService\n",
    "from tts_service import TTSService\n",
    "from embedding_service import EmbeddingService\n",
    "from enums import Language\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def run_live_demo(duration=10):\n",
    "    print(f\"--- Live Demo (Enrollment: {duration}s) ---\")\n",
    "    \n",
    "    # Initialize services\n",
    "    asr = ASRService()\n",
    "    translator = TranslationService()\n",
    "    tts = TTSService()\n",
    "    embedder = EmbeddingService()\n",
    "    \n",
    "    # 1. Record Input\n",
    "    try:\n",
    "        # Step 1: Listen and Transcribe\n",
    "        print(\"\\nRecording... (speak now)\")\n",
    "        english_text, source_audio_path = asr.listen_transcribe(duration=5)\n",
    "        print(f\"Transcribed: {english_text}\")\n",
    "        \n",
    "        # Step 2: Record Enrollment (Reference)\n",
    "        # Ideally we use the same audio if it's long enough, but let's record a dedicated style clip\n",
    "        # input(\"Press Enter to record style enrollment (speak clearly)...\")\n",
    "        # ref_path = asr.record_audio(duration=duration, file_path=\"demo_ref.wav\")\n",
    "        \n",
    "        # Simpler: Just use the input audio itself as reference (Zero-Shot on self)\n",
    "        ref_path = source_audio_path\n",
    "\n",
    "        # 2. Translate\n",
    "        spanish_text = translator.translate(english_text, target_language=Language.SPANISH)\n",
    "        print(f\"Translated: {spanish_text}\")\n",
    "\n",
    "        # 3. Synthesize\n",
    "        output_path = \"demo_output.wav\"\n",
    "        tts.synthesize(spanish_text, output_path, ref_path)\n",
    "        print(f\"Synthesized audio saved to {output_path}\")\n",
    "\n",
    "        # 4. Evaluate Similarity\n",
    "        gt_embedding = embedder.extract_embedding(ref_path)\n",
    "        out_embedding = embedder.extract_embedding(output_path)\n",
    "        \n",
    "        if gt_embedding.dim() == 1: gt_embedding = gt_embedding.unsqueeze(0)\n",
    "        if out_embedding.dim() == 1: out_embedding = out_embedding.unsqueeze(0)\n",
    "            \n",
    "        score = F.cosine_similarity(gt_embedding, out_embedding).item()\n",
    "        print(f\"Speaker Similarity Score: {score:.4f}\")\n",
    "        \n",
    "        # Playback (if in Colab/Jupyter)\n",
    "        from IPython.display import Audio, display\n",
    "        print(\"Original:\")\n",
    "        display(Audio(source_audio_path))\n",
    "        print(\"Synthesized (Spanish):\")\n",
    "        display(Audio(output_path))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during demo: {e}\")\n",
    "        print(\"Note: Microphone recording might fail on remote servers without audio forwarding.\")\n",
    "\n",
    "# run_live_demo(duration=10)\n",
    "# To run this on Colab, you'd typically need a Javascript helper to record audio from the browser,\n",
    "# as 'sounddevice' tries to access the server's mic (which doesn't exist).\n",
    "# For now, this code works if running locally."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
